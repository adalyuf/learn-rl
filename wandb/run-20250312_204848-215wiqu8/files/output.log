Epoch: 1 	Training Loss: 1.84 	Validation Loss: 0.46
[34m[1mwandb[0m: [33mWARNING[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[0m: [33mWARNING[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
Validation loss reduced from inf to 0.46. Saving model
Epoch: 2 	Training Loss: 1.84 	Validation Loss: 0.45
Validation loss reduced from 0.46 to 0.45. Saving model
Epoch: 3 	Training Loss: 1.66 	Validation Loss: 0.39
Validation loss reduced from 0.45 to 0.39. Saving model
Epoch: 4 	Training Loss: 1.48 	Validation Loss: 0.35
Validation loss reduced from 0.39 to 0.35. Saving model
Epoch: 5 	Training Loss: 1.36 	Validation Loss: 0.33
Validation loss reduced from 0.35 to 0.33. Saving model
Epoch: 6 	Training Loss: 1.27 	Validation Loss: 0.33
Epoch: 7 	Training Loss: 1.21 	Validation Loss: 0.29
Validation loss reduced from 0.33 to 0.29. Saving model
Epoch: 8 	Training Loss: 1.16 	Validation Loss: 0.29
Validation loss reduced from 0.29 to 0.29. Saving model
Epoch: 9 	Training Loss: 1.12 	Validation Loss: 0.27
Validation loss reduced from 0.29 to 0.27. Saving model
Epoch: 10 	Training Loss: 1.07 	Validation Loss: 0.27
Validation loss reduced from 0.27 to 0.27. Saving model
Epoch: 11 	Training Loss: 1.03 	Validation Loss: 0.25
Validation loss reduced from 0.27 to 0.25. Saving model
Epoch: 12 	Training Loss: 0.99 	Validation Loss: 0.24
Validation loss reduced from 0.25 to 0.24. Saving model
Epoch: 13 	Training Loss: 0.94 	Validation Loss: 0.24
Epoch: 14 	Training Loss: 0.90 	Validation Loss: 0.25
Epoch: 15 	Training Loss: 0.86 	Validation Loss: 0.22
Validation loss reduced from 0.24 to 0.22. Saving model
